{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b844041-919f-473f-bd2c-87ab463f8546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Fecha', 'Fecha.1', 'T (C)', 'Td (C)', 'Hr %', 'Tmax (C)', 'Tmin (C)', 'ddd', 'ff kmh', 'P0 hPa', 'P mar hPa', 'P Tnd', 'Prec (mm)', 'N t', 'N h', 'H Km', 'Inso D-1', 'Vis km', 'WW', 'W1', 'W2']\n",
      "        Fecha Fecha.1 T (C)  Td (C)  Hr % Tmax (C) Tmin (C)  ddd  ff kmh  \\\n",
      "0  01/07/2025   00:00  28.2    23.7  77.0    -----     24.1    E     3.6   \n",
      "1  30/06/2025   21:00  24.7    23.9  95.0    -----    -----    E     3.6   \n",
      "2  30/06/2025   18:00  25.0    24.2  95.0    -----    -----  CAL     0.0   \n",
      "3  30/06/2025   15:00  25.5    24.6  95.0    -----    -----  CAL     0.0   \n",
      "4  30/06/2025   12:00  26.0    24.8  93.0     31.3    -----  SSW     3.6   \n",
      "\n",
      "   P0 hPa  ...  P Tnd  Prec (mm)  N t  N h  H Km  Inso D-1 Vis km  WW  W1  W2  \n",
      "0  1003.4  ...    0.6   11.0/24h  5.0  1.0   0.6       3.6    8.0 NaN NaN NaN  \n",
      "1  1002.8  ...   -0.0       ----  5.0  1.0   0.6       ---    7.0 NaN NaN NaN  \n",
      "2  1002.8  ...   -0.8     0.0/6h  7.0  2.0   0.6       ---    7.0 NaN NaN NaN  \n",
      "3  1003.6  ...    0.1       ----  7.0  1.0   0.6       ---    7.0 NaN NaN NaN  \n",
      "4  1003.5  ...    1.6     8.0/6h  8.0  6.0   0.3       ---    7.0 NaN NaN NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "    datetime wind_dir  wind_speed\n",
      "0 2025-07-01        E         3.6\n",
      "1 2025-06-30        E         3.6\n",
      "2 2025-06-30      CAL         0.0\n",
      "3 2025-06-30      CAL         0.0\n",
      "4 2025-06-30      SSW         3.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.ogimet.com/cgi-bin/gsynres?ind=98430&decoded=yes&ndays=2&ano=2025&mes=07&day=01&hora=00\"\n",
    "\n",
    "# Read table with the first row as header\n",
    "df = pd.read_html(url, header=0)[0]\n",
    "\n",
    "# Check what columns we got\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "# Parse datetime (Fecha + Hora combined into one column here)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"Fecha\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Keep only wind columns\n",
    "wind_df = df[[\"datetime\", \"ddd\", \"ff kmh\"]].copy()\n",
    "wind_df.rename(columns={\"ddd\": \"wind_dir\", \"ff kmh\": \"wind_speed\"}, inplace=True)\n",
    "\n",
    "print(wind_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf02456f-7f1b-4da3-b5b8-a96b832e1b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Got 7 rows for 2025-01-01\n",
      "✅ Got 9 rows for 2025-01-02\n",
      "✅ Got 9 rows for 2025-01-03\n",
      "✅ Got 9 rows for 2025-01-04\n",
      "✅ Got 9 rows for 2025-01-05\n",
      "✅ Got 9 rows for 2025-01-06\n",
      "✅ Got 9 rows for 2025-01-07\n",
      "✅ Got 9 rows for 2025-01-08\n",
      "✅ Got 9 rows for 2025-01-09\n",
      "✅ Got 9 rows for 2025-01-10\n",
      "✅ Got 9 rows for 2025-01-11\n",
      "✅ Got 9 rows for 2025-01-12\n",
      "✅ Got 9 rows for 2025-01-13\n",
      "✅ Got 9 rows for 2025-01-14\n",
      "✅ Got 9 rows for 2025-01-15\n",
      "✅ Got 9 rows for 2025-01-16\n",
      "✅ Got 9 rows for 2025-01-17\n",
      "✅ Got 9 rows for 2025-01-18\n",
      "✅ Got 9 rows for 2025-01-19\n",
      "✅ Got 9 rows for 2025-01-20\n",
      "✅ Got 9 rows for 2025-01-21\n",
      "✅ Got 9 rows for 2025-01-22\n",
      "✅ Got 9 rows for 2025-01-23\n",
      "✅ Got 9 rows for 2025-01-24\n",
      "✅ Got 9 rows for 2025-01-25\n",
      "✅ Got 9 rows for 2025-01-26\n",
      "✅ Got 9 rows for 2025-01-27\n",
      "✅ Got 9 rows for 2025-01-28\n",
      "✅ Got 9 rows for 2025-01-29\n",
      "✅ Got 9 rows for 2025-01-30\n",
      "✅ Got 9 rows for 2025-01-31\n",
      "✅ Got 9 rows for 2025-02-01\n",
      "✅ Got 9 rows for 2025-02-02\n",
      "✅ Got 9 rows for 2025-02-03\n",
      "✅ Got 9 rows for 2025-02-04\n",
      "✅ Got 9 rows for 2025-02-05\n",
      "✅ Got 9 rows for 2025-02-06\n",
      "✅ Got 9 rows for 2025-02-07\n",
      "✅ Got 9 rows for 2025-02-08\n",
      "✅ Got 9 rows for 2025-02-09\n",
      "✅ Got 9 rows for 2025-02-10\n",
      "✅ Got 9 rows for 2025-02-11\n",
      "✅ Got 9 rows for 2025-02-12\n",
      "✅ Got 9 rows for 2025-02-13\n",
      "✅ Got 9 rows for 2025-02-14\n",
      "✅ Got 9 rows for 2025-02-15\n",
      "✅ Got 9 rows for 2025-02-16\n",
      "✅ Got 9 rows for 2025-02-17\n",
      "✅ Got 9 rows for 2025-02-18\n",
      "✅ Got 9 rows for 2025-02-19\n",
      "✅ Got 9 rows for 2025-02-20\n",
      "✅ Got 9 rows for 2025-02-21\n",
      "✅ Got 9 rows for 2025-02-22\n",
      "✅ Got 9 rows for 2025-02-23\n",
      "✅ Got 9 rows for 2025-02-24\n",
      "✅ Got 9 rows for 2025-02-25\n",
      "✅ Got 9 rows for 2025-02-26\n",
      "✅ Got 9 rows for 2025-02-27\n",
      "✅ Got 9 rows for 2025-02-28\n",
      "✅ Got 9 rows for 2025-03-01\n",
      "✅ Got 9 rows for 2025-03-02\n",
      "✅ Got 9 rows for 2025-03-03\n",
      "✅ Got 9 rows for 2025-03-04\n",
      "✅ Got 9 rows for 2025-03-05\n",
      "✅ Got 9 rows for 2025-03-06\n",
      "✅ Got 9 rows for 2025-03-07\n",
      "✅ Got 9 rows for 2025-03-08\n",
      "✅ Got 9 rows for 2025-03-09\n",
      "✅ Got 9 rows for 2025-03-10\n",
      "✅ Got 9 rows for 2025-03-11\n",
      "✅ Got 9 rows for 2025-03-12\n",
      "✅ Got 9 rows for 2025-03-13\n",
      "✅ Got 9 rows for 2025-03-14\n",
      "✅ Got 9 rows for 2025-03-15\n",
      "✅ Got 9 rows for 2025-03-16\n",
      "✅ Got 9 rows for 2025-03-17\n",
      "✅ Got 9 rows for 2025-03-18\n",
      "✅ Got 9 rows for 2025-03-19\n",
      "✅ Got 9 rows for 2025-03-20\n",
      "✅ Got 9 rows for 2025-03-21\n",
      "✅ Got 9 rows for 2025-03-22\n",
      "✅ Got 9 rows for 2025-03-23\n",
      "✅ Got 9 rows for 2025-03-24\n",
      "✅ Got 9 rows for 2025-03-25\n",
      "✅ Got 9 rows for 2025-03-26\n",
      "✅ Got 9 rows for 2025-03-27\n",
      "✅ Got 9 rows for 2025-03-28\n",
      "✅ Got 9 rows for 2025-03-29\n",
      "✅ Got 9 rows for 2025-03-30\n",
      "✅ Got 9 rows for 2025-03-31\n",
      "✅ Got 9 rows for 2025-04-01\n",
      "✅ Got 9 rows for 2025-04-02\n",
      "✅ Got 9 rows for 2025-04-03\n",
      "✅ Got 9 rows for 2025-04-04\n",
      "✅ Got 9 rows for 2025-04-05\n",
      "✅ Got 9 rows for 2025-04-06\n",
      "✅ Got 9 rows for 2025-04-07\n",
      "✅ Got 9 rows for 2025-04-08\n",
      "✅ Got 9 rows for 2025-04-09\n",
      "✅ Got 9 rows for 2025-04-10\n",
      "✅ Got 8 rows for 2025-04-11\n",
      "✅ Got 9 rows for 2025-04-12\n",
      "✅ Got 9 rows for 2025-04-13\n",
      "✅ Got 9 rows for 2025-04-14\n",
      "✅ Got 9 rows for 2025-04-15\n",
      "✅ Got 9 rows for 2025-04-16\n",
      "✅ Got 9 rows for 2025-04-17\n",
      "✅ Got 9 rows for 2025-04-18\n",
      "✅ Got 9 rows for 2025-04-19\n",
      "✅ Got 9 rows for 2025-04-20\n",
      "✅ Got 9 rows for 2025-04-21\n",
      "✅ Got 9 rows for 2025-04-22\n",
      "✅ Got 9 rows for 2025-04-23\n",
      "✅ Got 9 rows for 2025-04-24\n",
      "✅ Got 9 rows for 2025-04-25\n",
      "✅ Got 9 rows for 2025-04-26\n",
      "✅ Got 9 rows for 2025-04-27\n",
      "✅ Got 9 rows for 2025-04-28\n",
      "✅ Got 9 rows for 2025-04-29\n",
      "✅ Got 9 rows for 2025-04-30\n",
      "✅ Got 9 rows for 2025-05-01\n",
      "✅ Got 9 rows for 2025-05-02\n",
      "✅ Got 9 rows for 2025-05-03\n",
      "✅ Got 9 rows for 2025-05-04\n",
      "✅ Got 9 rows for 2025-05-05\n",
      "✅ Got 9 rows for 2025-05-06\n",
      "✅ Got 9 rows for 2025-05-07\n",
      "✅ Got 9 rows for 2025-05-08\n",
      "✅ Got 9 rows for 2025-05-09\n",
      "✅ Got 9 rows for 2025-05-10\n",
      "✅ Got 9 rows for 2025-05-11\n",
      "✅ Got 9 rows for 2025-05-12\n",
      "✅ Got 9 rows for 2025-05-13\n",
      "✅ Got 9 rows for 2025-05-14\n",
      "✅ Got 9 rows for 2025-05-15\n",
      "✅ Got 9 rows for 2025-05-16\n",
      "✅ Got 9 rows for 2025-05-17\n",
      "✅ Got 9 rows for 2025-05-18\n",
      "✅ Got 9 rows for 2025-05-19\n",
      "✅ Got 9 rows for 2025-05-20\n",
      "✅ Got 9 rows for 2025-05-21\n",
      "✅ Got 9 rows for 2025-05-22\n",
      "✅ Got 9 rows for 2025-05-23\n",
      "✅ Got 9 rows for 2025-05-24\n",
      "✅ Got 9 rows for 2025-05-25\n",
      "✅ Got 9 rows for 2025-05-26\n",
      "✅ Got 9 rows for 2025-05-27\n",
      "✅ Got 9 rows for 2025-05-28\n",
      "✅ Got 9 rows for 2025-05-29\n",
      "✅ Got 9 rows for 2025-05-30\n",
      "✅ Got 9 rows for 2025-05-31\n",
      "✅ Got 9 rows for 2025-06-01\n",
      "✅ Got 9 rows for 2025-06-02\n",
      "✅ Got 9 rows for 2025-06-03\n",
      "✅ Got 9 rows for 2025-06-04\n",
      "✅ Got 9 rows for 2025-06-05\n",
      "✅ Got 9 rows for 2025-06-06\n",
      "✅ Got 9 rows for 2025-06-07\n",
      "✅ Got 9 rows for 2025-06-08\n",
      "✅ Got 9 rows for 2025-06-09\n",
      "✅ Got 9 rows for 2025-06-10\n",
      "✅ Got 9 rows for 2025-06-11\n",
      "✅ Got 9 rows for 2025-06-12\n",
      "✅ Got 9 rows for 2025-06-13\n",
      "✅ Got 9 rows for 2025-06-14\n",
      "✅ Got 9 rows for 2025-06-15\n",
      "✅ Got 9 rows for 2025-06-16\n",
      "✅ Got 9 rows for 2025-06-17\n",
      "✅ Got 9 rows for 2025-06-18\n",
      "✅ Got 9 rows for 2025-06-19\n",
      "✅ Got 9 rows for 2025-06-20\n",
      "✅ Got 9 rows for 2025-06-21\n",
      "✅ Got 9 rows for 2025-06-22\n",
      "✅ Got 9 rows for 2025-06-23\n",
      "✅ Got 10 rows for 2025-06-24\n",
      "✅ Got 9 rows for 2025-06-25\n",
      "✅ Got 9 rows for 2025-06-26\n",
      "✅ Got 9 rows for 2025-06-27\n",
      "✅ Got 9 rows for 2025-06-28\n",
      "✅ Got 9 rows for 2025-06-29\n",
      "✅ Got 9 rows for 2025-06-30\n",
      "✅ Got 9 rows for 2025-07-01\n",
      "✅ Got 9 rows for 2025-07-02\n",
      "✅ Got 9 rows for 2025-07-03\n",
      "✅ Got 9 rows for 2025-07-04\n",
      "✅ Got 9 rows for 2025-07-05\n",
      "✅ Got 9 rows for 2025-07-06\n",
      "✅ Got 9 rows for 2025-07-07\n",
      "✅ Got 9 rows for 2025-07-08\n",
      "✅ Got 9 rows for 2025-07-09\n",
      "✅ Got 9 rows for 2025-07-10\n",
      "✅ Got 9 rows for 2025-07-11\n",
      "✅ Got 9 rows for 2025-07-12\n",
      "✅ Got 9 rows for 2025-07-13\n",
      "✅ Got 9 rows for 2025-07-14\n",
      "✅ Got 9 rows for 2025-07-15\n",
      "✅ Got 9 rows for 2025-07-16\n",
      "✅ Got 9 rows for 2025-07-17\n",
      "✅ Got 9 rows for 2025-07-18\n",
      "✅ Got 9 rows for 2025-07-19\n",
      "✅ Got 9 rows for 2025-07-20\n",
      "✅ Got 9 rows for 2025-07-21\n",
      "✅ Got 9 rows for 2025-07-22\n",
      "✅ Got 9 rows for 2025-07-23\n",
      "✅ Got 9 rows for 2025-07-24\n",
      "✅ Got 9 rows for 2025-07-25\n",
      "✅ Got 9 rows for 2025-07-26\n",
      "✅ Got 9 rows for 2025-07-27\n",
      "✅ Got 9 rows for 2025-07-28\n",
      "✅ Got 9 rows for 2025-07-29\n",
      "✅ Got 9 rows for 2025-07-30\n",
      "✅ Got 9 rows for 2025-07-31\n",
      "             datetime wind_dir  wind_speed  wind_dir_deg\n",
      "0 2024-12-31 03:00:00        E         3.6          90.0\n",
      "1 2024-12-31 06:00:00        W         7.2         270.0\n",
      "2 2024-12-31 09:00:00      SSW         3.6         202.5\n",
      "3 2024-12-31 12:00:00       NE         3.6          45.0\n",
      "4 2024-12-31 15:00:00      CAL         0.0           NaN\n",
      "                datetime wind_dir  wind_speed  wind_dir_deg\n",
      "1901 2025-07-30 12:00:00        S         3.6         180.0\n",
      "1902 2025-07-30 15:00:00       SW         3.6         225.0\n",
      "1903 2025-07-30 18:00:00        S         3.6         180.0\n",
      "1904 2025-07-30 21:00:00      WSW         7.2         247.5\n",
      "1905 2025-07-31 00:00:00       SW        10.8         225.0\n",
      "✅ Saved full dataset to winds_science_garden_JanJul2025.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Mapping compass directions to degrees\n",
    "def wind_dir_to_degrees(direction):\n",
    "    mapping = {\n",
    "        \"N\": 0, \"NNE\": 22.5, \"NE\": 45, \"ENE\": 67.5,\n",
    "        \"E\": 90, \"ESE\": 112.5, \"SE\": 135, \"SSE\": 157.5,\n",
    "        \"S\": 180, \"SSW\": 202.5, \"SW\": 225, \"WSW\": 247.5,\n",
    "        \"W\": 270, \"WNW\": 292.5, \"NW\": 315, \"NNW\": 337.5,\n",
    "        \"CAL\": None\n",
    "    }\n",
    "    return mapping.get(direction, None)\n",
    "\n",
    "def get_ogimet_wind(station=\"98430\", start=\"2025-01-01\", ndays=1, hour=0):\n",
    "    \"\"\"Scrape hourly wind data from Ogimet for given start + ndays.\"\"\"\n",
    "    y, m, d = start.split(\"-\")\n",
    "    url = (\n",
    "        f\"https://www.ogimet.com/cgi-bin/gsynres?\"\n",
    "        f\"ind={station}&decoded=yes&ndays={ndays}&ano={y}&mes={m}&day={d}&hora={hour:02d}\"\n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_html(url, header=0)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed for {start}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Merge date + time\n",
    "    df[\"datetime\"] = pd.to_datetime(\n",
    "        df[\"Fecha\"] + \" \" + df[\"Fecha.1\"],\n",
    "        format=\"%d/%m/%Y %H:%M\",\n",
    "        dayfirst=True,\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    wind_df = df[[\"datetime\", \"ddd\", \"ff kmh\"]].copy()\n",
    "    wind_df.rename(columns={\"ddd\": \"wind_dir\", \"ff kmh\": \"wind_speed\"}, inplace=True)\n",
    "    wind_df[\"wind_dir_deg\"] = wind_df[\"wind_dir\"].apply(wind_dir_to_degrees)\n",
    "\n",
    "    return wind_df.dropna(subset=[\"datetime\"])\n",
    "\n",
    "# ============================\n",
    "# Collect data from Jan 1 – Jul 31, 2025\n",
    "# ============================\n",
    "\n",
    "station = \"98430\"\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date   = datetime(2025, 7, 31)\n",
    "\n",
    "all_data = []\n",
    "current = start_date\n",
    "\n",
    "while current <= end_date:\n",
    "    chunk = get_ogimet_wind(\n",
    "        station=station, start=current.strftime(\"%Y-%m-%d\"), ndays=1\n",
    "    )\n",
    "    if not chunk.empty:\n",
    "        all_data.append(chunk)\n",
    "        print(f\"✅ Got {len(chunk)} rows for {current.date()}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No data for {current.date()}\")\n",
    "\n",
    "    current += timedelta(days=1)\n",
    "    time.sleep(1)  # polite delay so Ogimet doesn’t block\n",
    "\n",
    "# Merge\n",
    "winds_full = pd.concat(all_data, ignore_index=True)\n",
    "winds_full = winds_full.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "print(winds_full.head())\n",
    "print(winds_full.tail())\n",
    "\n",
    "# Save to CSV\n",
    "winds_full.to_csv(\"winds_science_garden_JanJul2025.csv\", index=False)\n",
    "print(\"✅ Saved full dataset to winds_science_garden_JanJul2025.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAREAQI",
   "language": "python",
   "name": "careaqi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
